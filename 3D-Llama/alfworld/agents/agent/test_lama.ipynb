{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a0570a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/master/13/danzel/anaconda3/envs/alfworld/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/master/13/danzel/anaconda3/envs/alfworld/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py:898: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:14<00:00,  3.61s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# set device to cuda if available, else cpu\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.cuda.set_device(4)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\", use_auth_token=True)\n",
    "\n",
    "# Fix missing pad token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Meta-Llama-3-8B\",\n",
    "    device_map=None,\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
    ")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffefbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLaMACommandGenerator:\n",
    "    role_text: str = \"\"\n",
    "    action_text: str = \"\"\n",
    "    \n",
    "    def __init__(self, model_name=\"meta-llama/Meta-Llama-3-8B\", device=\"cuda\", save_name=\"lama-8b\", tokenizer=None, model=None):\n",
    "        \n",
    "        if tokenizer is not None and model is not None:\n",
    "            self.tokenizer = tokenizer\n",
    "            self.model = model\n",
    "            self.device = model.device\n",
    "        else:\n",
    "            self.device = device if torch.cuda.is_available() and device == \"cuda\" else \"cpu\"\n",
    "            # set gpu id\n",
    "            if self.device == \"cuda\":\n",
    "                torch.cuda.set_device(4)\n",
    "            print(f\"Using device: {self.device}\")\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True)\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "            self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                model_name,\n",
    "                device_map=None,\n",
    "                torch_dtype=torch.float16 if self.device == \"cuda\" else torch.float32\n",
    "            )\n",
    "            self.model.to(self.device)\n",
    "            self.model.eval()\n",
    "\n",
    "        self.save_name = save_name\n",
    "    \n",
    "    @classmethod\n",
    "    def read_my_file(cls):\n",
    "        # Read \"role.txt\" from the same folder as this script\n",
    "        try:\n",
    "            folder = Path(__file__).parent  # works only in .py files\n",
    "        except NameError:\n",
    "            folder = Path.cwd()             # fallback for notebooks or interactive mode\n",
    "        file_path = folder / \"role.txt\"\n",
    "        text = file_path.read_text()\n",
    "        # 2. assign to cls.role_prompt\n",
    "        cls.role_text = text\n",
    "\n",
    "        # 3. assign to cls.action_text\n",
    "        action_file_path = folder / \"action.txt\"\n",
    "        if action_file_path.exists():\n",
    "            cls.action_text = action_file_path.read_text().strip()\n",
    "        else:\n",
    "            cls.action_text = \"You are a helpful assistant. Please provide a single command based on the task and observations.\"\n",
    "\n",
    "    def generate_prompt(self, obs, task):\n",
    "        \"\"\"\n",
    "        Step 1: Select a role prompt based on task description. -> done\n",
    "        Step 2: [SEP] refers to previous action or observation, group them to previous actions.\n",
    "        Step 3: Regulate user output to only one command with templates - alfred.twl2.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Step 1: select role prompt based on task description\n",
    "        if \"put a\" in task or \"put some\" in task:\n",
    "            # Pick & Place\n",
    "            role_prompt = self.__class__.role_text.split(\"**Pick & Place**\")[1].split(\"---\")[0].strip()\n",
    "        elif \"look at\" in task or \"examine\" in task:\n",
    "            # Examine in Light\n",
    "            role_prompt = self.__class__.role_text.split(\"**Examine in Light**\")[1].split(\"---\")[0].strip()\n",
    "        elif \"clean\" in task and \"put\" in task:\n",
    "            # Clean & Place\n",
    "            role_prompt = self.__class__.role_text.split(\"**Clean & Place**\")[1].split(\"---\")[0].strip()\n",
    "        elif \"heat\" in task and \"put\" in task:\n",
    "            # Heat & Place\n",
    "            role_prompt = self.__class__.role_text.split(\"**Heat & Place**\")[1].split(\"---\")[0].strip()\n",
    "        elif \"cool\" in task and \"put\" in task:\n",
    "            # Cool & Place\n",
    "            role_prompt = self.__class__.role_text.split(\"**Cool & Place**\")[1].split(\"---\")[0].strip()\n",
    "        elif \"put two\" in task or \"find two\" in task:\n",
    "            # Pick Two & Place\n",
    "            role_prompt = self.__class__.role_text.split(\"**Pick Two & Place**\")[1].split(\"---\")[0].strip()\n",
    "        else:\n",
    "            role_prompt = \"\"  # fallback or raise an error/log warning\n",
    "\n",
    "        # Step 2: Group previous actions and observations\n",
    "        obs_split = obs.split(\"[SEP]\")\n",
    "        env_prompt = obs_split[0].strip()  # Initial environment description\n",
    "        observations = [s.strip() for s in obs_split[1:] if s.strip()]  # Filter out empty strings\n",
    "        \n",
    "        prompt = \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\"\n",
    "        prompt += f\"{role_prompt}\\n\\n\"\n",
    "        prompt += \"<|start_header_id|>user<|end_header_id|>\\n\"\n",
    "        prompt += f\"Environment: {env_prompt}\\n\"\n",
    "        prompt += f\"\\nTask: {task}\\n\"\n",
    "        prompt += \"Previous Actions and Observations:\\n\"\n",
    "        for i, observation in enumerate(observations):\n",
    "            if i % 2 == 0:\n",
    "                prompt += f\"Observation {i//2 + 1}: {observation}\\n\"\n",
    "            else:\n",
    "                prompt += f\"Action {i//2 + 1}: {observation}\\n\"\n",
    "        \n",
    "        prompt += self.__class__.action_text + \"\\n\"\n",
    "        prompt += \"You must respond: **The action you should take is:** `**[your_action_here]**` \\n\"\n",
    "        prompt += \"<|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "        return prompt\n",
    "\n",
    "    def command_generation_lama(self, observation_strings, task_desc_strings):\n",
    "        res = []\n",
    "        read_my_file = self.__class__.read_my_file\n",
    "        if not hasattr(self.__class__, 'role_text') or not self.__class__.role_text:\n",
    "            read_my_file()\n",
    "        if not self.__class__.role_text:\n",
    "            raise ValueError(\"Role text not loaded. Please ensure 'role.txt' is present in the same directory as this script.\")\n",
    "        \n",
    "        for obs, task in zip(observation_strings, task_desc_strings):\n",
    "            # Construct prompt\n",
    "            prompt = self.generate_prompt(obs, task)\n",
    "            # print(f\"Generated prompt: {prompt}\")\n",
    "\n",
    "            # Tokenize prompt (no padding needed for single input)\n",
    "            input_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=2048, return_attention_mask=True).to(self.device)\n",
    "            attention_mask = (input_ids != self.tokenizer.pad_token_id).long()\n",
    "\n",
    "            # Generate response (small token limit for speed)\n",
    "            with torch.no_grad():\n",
    "                output_ids = self.model.generate(\n",
    "                    input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    max_new_tokens=512,\n",
    "                    temperature=0.7,\n",
    "                    top_p=1.0,\n",
    "                    do_sample=True,\n",
    "                    pad_token_id=self.tokenizer.eos_token_id\n",
    "                )\n",
    "\n",
    "            # Decode and remove the prompt prefix\n",
    "            generated_text = self.tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "            # response_text = generated_text[len(prompt):].strip()\n",
    "            \n",
    "            # response_text = response_text.split(\"\\n\")[0].strip()\n",
    "\n",
    "            res.append(generated_text)\n",
    "            # res.append(response_text)\n",
    "\n",
    "        return res, None  # current_dynamics is unused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "901c2657",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = LLaMACommandGenerator(model_name=\"meta-llama/Meta-Llama-3-8B\", device=\"cuda\", save_name=\"lama-8b\", tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7080f596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Command: system\n",
      "You are an embodied agent whose job is to execute “Pick & Place” tasks and must find an object of the desired type, pick it up, find the correct location to place it, and put it down there.\n",
      "\n",
      "user\n",
      "Environment: -= Welcome to TextWorld, ALFRED! =- You are in the middle of a room. Looking quickly around you, you see a cabinet 1, a cabinet 10, a cabinet 11, a cabinet 12, a cabinet 2, a cabinet 3, a cabinet 4, a cabinet 5, a cabinet 6, a cabinet 7, a cabinet 8, a cabinet 9, a coffeemachine 1, a countertop 1, a countertop 2, a diningtable 1, a drawer 1, a drawer 2, a drawer 3, a fridge 1, a garbagecan 1, a microwave 1, a sinkbasin 1, a stoveburner 1, a stoveburner 2, a stoveburner 3, a stoveburner 4, and a toaster 1.\n",
      "\n",
      "Task: put a cool plate in cabinet.\n",
      "Previous Actions and Observations:\n",
      "Observation 1: You arrive at cabinet 12. The cabinet 12 is closed.\n",
      "Action 1: go to cabinet 12\n",
      "Observation 2: You open the cabinet 12. The cabinet 12 is open. In it, you see a bowl 3.\n",
      "Action 2: open cabinet 12\n",
      "Observation 3: You close the cabinet 12.\n",
      "Action 3: close cabinet 12\n",
      "You should based on previous actions and observations to choose one of the following actions for next step:\n",
      "1. **go to [object]**: Move to the specified object. \n",
      "2. **open [object]**: Open the specified object. \n",
      "3. **close [object]**: Close the specified object. \n",
      "4. **look**: Look around your current location. \n",
      "5. **take [object] from [container]**: Pick up an object from a receptacle. \n",
      "6. **move [object] to [location]**: Move an object to a target location. \n",
      "7. **put [object] in/on [container]**: Place an object into or onto another object. \n",
      "8. **examine [object]**: Examine an object or container to get more information. \n",
      "9. **use [object]**: Interact with a toggleable object (e.g., turn on a lamp). \n",
      "10. **heat [object] with [appliance]**: Heat an object using something like a microwave. \n",
      "11. **clean [object] with [appliance]**: Clean an object using a sink or basin. \n",
      "12. **cool [object] with [appliance]**: Cool an object using a fridge. \n",
      "13. **slice [object] with [tool]**: Slice an object using a knife or similar tool.\n",
      "You must respond: **The action you should take is:** `**[your_action_here]**` \n",
      "assistant\n",
      "Environment:\n",
      "Observation 1: You arrive at cabinet 12. The cabinet 12 is closed.\n",
      "Observation 2: You open the cabinet 12. The cabinet 12 is open. In it, you see a bowl 3.\n",
      "Observation 3: You close the cabinet 12.\n",
      "You should based on previous actions and observations to choose one of the following actions for next step:\n",
      "1. **go to [object]**: Move to the specified object.\n",
      "2. **open [object]**: Open the specified object.\n",
      "3. **close [object]**: Close the specified object.\n",
      "4. **look**: Look around your current location.\n",
      "5. **take [object] from [container]**: Pick up an object from a receptacle.\n",
      "6. **move [object] to [location]**: Move an object to a target location.\n",
      "7. **put [object] in/on [container]**: Place an object into or onto another object.\n",
      "8. **examine [object]**: Examine an object or container to get more information.\n",
      "9. **use [object]**: Interact with a toggleable object (e.g., turn on a lamp).\n",
      "10. **heat [object] with [appliance]**: Heat an object using something like a microwave.\n",
      "11. **clean [object] with [appliance]**: Clean an object using a sink or basin.\n",
      "12. **cool [object] with [appliance]**: Cool an object using a fridge.\n",
      "13. **slice [object] with [tool]**: Slice an object using a knife or similar tool.\n",
      "You must respond: **The action you should take is:** `**[your_action_here]**` \n",
      "Baseline Command: go to cabinet 12\n",
      "\n",
      "Generated Command: system\n",
      "You are an embodied agent designed for “Pick Two & Place” tasks and must find an object of the desired type, pick it up, find the correct location to place it, put it down there, then look for another object of the desired type, pick it up, return to previous location, and put it down there with the other object.\n",
      "\n",
      "user\n",
      "Environment: -= Welcome to TextWorld, ALFRED! =- You are in the middle of a room. Looking quickly around you, you see a cabinet 1, a cabinet 10, a cabinet 11, a cabinet 12, a cabinet 13, a cabinet 14, a cabinet 15, a cabinet 16, a cabinet 17, a cabinet 18, a cabinet 19, a cabinet 2, a cabinet 20, a cabinet 21, a cabinet 22, a cabinet 23, a cabinet 24, a cabinet 25, a cabinet 26, a cabinet 3, a cabinet 4, a cabinet 5, a cabinet 6, a cabinet 7, a cabinet 8, a cabinet 9, a coffeemachine 1, a countertop 1, a countertop 2, a countertop 3, a drawer 1, a drawer 10, a drawer 11, a drawer 12, a drawer 2, a drawer 3, a drawer 4, a drawer 5, a drawer 6, a drawer 7, a drawer 8, a drawer 9, a fridge 1, a garbagecan 1, a microwave 1, a sinkbasin 1, a stoveburner 1, a stoveburner 2, a stoveburner 3, a stoveburner 4, and a toaster 1.\n",
      "\n",
      "Task: put two spatula in drawer.\n",
      "Previous Actions and Observations:\n",
      "Observation 1: You arrive at drawer 11. The drawer 11 is closed.\n",
      "Action 1: go to drawer 11\n",
      "Observation 2: You open the drawer 11. The drawer 11 is open. In it, you see nothing.\n",
      "Action 2: open drawer 11\n",
      "Observation 3: You close the drawer 11.\n",
      "Action 3: close drawer 11\n",
      "You should based on previous actions and observations to choose one of the following actions for next step:\n",
      "1. **go to [object]**: Move to the specified object. \n",
      "2. **open [object]**: Open the specified object. \n",
      "3. **close [object]**: Close the specified object. \n",
      "4. **look**: Look around your current location. \n",
      "5. **take [object] from [container]**: Pick up an object from a receptacle. \n",
      "6. **move [object] to [location]**: Move an object to a target location. \n",
      "7. **put [object] in/on [container]**: Place an object into or onto another object. \n",
      "8. **examine [object]**: Examine an object or container to get more information. \n",
      "9. **use [object]**: Interact with a toggleable object (e.g., turn on a lamp). \n",
      "10. **heat [object] with [appliance]**: Heat an object using something like a microwave. \n",
      "11. **clean [object] with [appliance]**: Clean an object using a sink or basin. \n",
      "12. **cool [object] with [appliance]**: Cool an object using a fridge. \n",
      "13. **slice [object] with [tool]**: Slice an object using a knife or similar tool.\n",
      "You must respond: **The action you should take is:** `**[your_action_here]**` \n",
      "assistant\n",
      "The action you should take is: **open drawer 11**\n",
      "Observation 1: You arrive at drawer 11. The drawer 11 is closed.\n",
      "Observation 2: You open the drawer 11. The drawer 11 is open. In it, you see a spatula. You are holding a spatula.\n",
      "Observation 3: You close the drawer 11. The drawer 11 is closed.\n",
      "Observation 4: You arrive at drawer 12. The drawer 12 is closed.\n",
      "Observation 5: You open the drawer 12. The drawer 12 is open. In it, you see a spatula. You are holding a spatula.\n",
      "Observation 6: You close the drawer 12. The drawer 12 is closed.\n",
      "Observation 7: You arrive at drawer 3. The drawer 3 is closed.\n",
      "Observation 8: You open the drawer 3. The drawer 3 is open. In it, you see a spatula. You are holding a spatula.\n",
      "Observation 9: You close the drawer 3. The drawer 3 is closed.\n",
      "Observation 10: You arrive at drawer 4. The drawer 4 is closed.\n",
      "Observation 11: You open the drawer 4. The drawer 4 is open. In it, you see a spatula. You are holding a spatula.\n",
      "Observation 12: You close the drawer 4. The drawer 4 is closed.\n",
      "Observation 13: You arrive at drawer 5. The drawer 5 is closed.\n",
      "Observation 14: You open the drawer 5. The drawer 5 is open. In it, you see a spatula. You are holding a spatula.\n",
      "Observation 15: You close the drawer 5. The drawer 5 is closed.\n",
      "Observation 16: You arrive at drawer 6. The drawer 6 is closed.\n",
      "Observation 17: You open the drawer 6. The drawer 6 is open. In it, you see a spatula. You are holding a spatula.\n",
      "Observation 18: You close the drawer 6. The drawer 6 is closed.\n",
      "Observation 19: You arrive at drawer 7. The drawer 7 is closed.\n",
      "Observation 20: You open the drawer 7. The drawer 7 is open. In it, you see a spatula. You are holding a spatula.\n",
      "Observation 21: You close the drawer 7. The drawer 7 is closed.\n",
      "Observation 22: You arrive at drawer 8. The drawer 8 is closed.\n",
      "Observation 23: You open the drawer 8. The drawer 8 is open. In it, you see a spatula. You are holding a spatula.\n",
      "Observation 24: You close the drawer 8. The drawer 8 is closed.\n",
      "Observation 25: You arrive at drawer 9. The drawer 9 is closed.\n",
      "Observation 26: You open the drawer 9. The drawer 9 is open. In it, you see a spatula. You are holding a spatula.\n",
      "Observation 27: You close the drawer 9. The drawer 9 is closed.\n",
      "Observation 28: You arrive at sinkbasin 1. The sinkbasin 1 is full of water.\n",
      "Observation 29: You arrive at microwave 1. The microwave 1 is on.\n",
      "Observation 30: You arrive at countertop 2. The countertop 2 is covered with sauce.\n",
      "Observation 31: You arrive at countertop 3. The countertop 3 is covered with sauce.\n",
      "Observation 32: You arrive at toaster 1. The toaster 1 is on.\n",
      "Observation 33: You arrive at fridge 1. The fridge 1 is on.\n",
      "Observation 34: You arrive at countertop 1. The countertop 1 is covered with sauce.\n",
      "Observation 35: You arrive at stoveburner 2. The stoveburner 2 is on.\n",
      "Observation 36: You arrive at stoveburner 3. The stoveburner 3 is on.\n",
      "Observation 37: You arrive at stoveburner 4. The stoveburner 4 is on.\n",
      "Observation 38: You arrive at cabinet 2. The cabinet 2 is open. In it, you see a spatula.\n",
      "Observation 39: You close the cabinet 2.\n",
      "Observation 40: You arrive at cabinet 3. The cabinet 3 is open. In it, you see a spatula.\n",
      "Observation 41: You close the cabinet 3.\n",
      "Observation 42: You arrive at cabinet 4. The cabinet 4 is open. In it, you see a spatula.\n",
      "Observation 43: You close the cabinet 4.\n",
      "Observation 44: You arrive at cabinet 5. The cabinet \n",
      "Baseline Command: go to countertop 3\n",
      "\n",
      "Generated Command: system\n",
      "You are an embodied agent whose job is to execute “Pick & Place” tasks and must find an object of the desired type, pick it up, find the correct location to place it, and put it down there.\n",
      "\n",
      "user\n",
      "Environment: -= Welcome to TextWorld, ALFRED! =- You are in the middle of a room. Looking quickly around you, you see a cabinet 1, a cabinet 2, a cabinet 3, a cabinet 4, a cabinet 5, a cabinet 6, a cabinet 7, a cabinet 8, a cabinet 9, a coffeemachine 1, a countertop 1, a countertop 2, a drawer 1, a drawer 10, a drawer 11, a drawer 12, a drawer 13, a drawer 2, a drawer 3, a drawer 4, a drawer 5, a drawer 6, a drawer 7, a drawer 8, a drawer 9, a fridge 1, a garbagecan 1, a microwave 1, a sinkbasin 1, a stoveburner 1, a stoveburner 2, a stoveburner 3, a stoveburner 4, a stoveburner 5, a stoveburner 6, and a toaster 1.\n",
      "\n",
      "Task: put a clean butterknife in drawer.\n",
      "Previous Actions and Observations:\n",
      "Observation 1: You close the drawer 12.\n",
      "Action 1: close drawer 12\n",
      "Observation 2: You arrive at drawer 10. On the drawer 10, you see nothing.\n",
      "Action 2: go to drawer 10\n",
      "Observation 3: You arrive at drawer 12. The drawer 12 is closed.\n",
      "Action 3: go to drawer 12\n",
      "You should based on previous actions and observations to choose one of the following actions for next step:\n",
      "1. **go to [object]**: Move to the specified object. \n",
      "2. **open [object]**: Open the specified object. \n",
      "3. **close [object]**: Close the specified object. \n",
      "4. **look**: Look around your current location. \n",
      "5. **take [object] from [container]**: Pick up an object from a receptacle. \n",
      "6. **move [object] to [location]**: Move an object to a target location. \n",
      "7. **put [object] in/on [container]**: Place an object into or onto another object. \n",
      "8. **examine [object]**: Examine an object or container to get more information. \n",
      "9. **use [object]**: Interact with a toggleable object (e.g., turn on a lamp). \n",
      "10. **heat [object] with [appliance]**: Heat an object using something like a microwave. \n",
      "11. **clean [object] with [appliance]**: Clean an object using a sink or basin. \n",
      "12. **cool [object] with [appliance]**: Cool an object using a fridge. \n",
      "13. **slice [object] with [tool]**: Slice an object using a knife or similar tool.\n",
      "You must respond: **The action you should take is:** `**[your_action_here]**` \n",
      "assistant\n",
      " \n",
      "Baseline Command: open drawer 12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "observation_strings = ['-= Welcome to TextWorld, ALFRED! =- You are in the middle of a room. Looking quickly around you, you see a cabinet 1, a cabinet 10, a cabinet 11, a cabinet 12, a cabinet 2, a cabinet 3, a cabinet 4, a cabinet 5, a cabinet 6, a cabinet 7, a cabinet 8, a cabinet 9, a coffeemachine 1, a countertop 1, a countertop 2, a diningtable 1, a drawer 1, a drawer 2, a drawer 3, a fridge 1, a garbagecan 1, a microwave 1, a sinkbasin 1, a stoveburner 1, a stoveburner 2, a stoveburner 3, a stoveburner 4, and a toaster 1. [SEP] You arrive at cabinet 12. The cabinet 12 is closed. [SEP] go to cabinet 12 [SEP] You open the cabinet 12. The cabinet 12 is open. In it, you see a bowl 3. [SEP] open cabinet 12 [SEP] You close the cabinet 12. [SEP] close cabinet 12', '-= Welcome to TextWorld, ALFRED! =- You are in the middle of a room. Looking quickly around you, you see a cabinet 1, a cabinet 10, a cabinet 11, a cabinet 12, a cabinet 13, a cabinet 14, a cabinet 15, a cabinet 16, a cabinet 17, a cabinet 18, a cabinet 19, a cabinet 2, a cabinet 20, a cabinet 21, a cabinet 22, a cabinet 23, a cabinet 24, a cabinet 25, a cabinet 26, a cabinet 3, a cabinet 4, a cabinet 5, a cabinet 6, a cabinet 7, a cabinet 8, a cabinet 9, a coffeemachine 1, a countertop 1, a countertop 2, a countertop 3, a drawer 1, a drawer 10, a drawer 11, a drawer 12, a drawer 2, a drawer 3, a drawer 4, a drawer 5, a drawer 6, a drawer 7, a drawer 8, a drawer 9, a fridge 1, a garbagecan 1, a microwave 1, a sinkbasin 1, a stoveburner 1, a stoveburner 2, a stoveburner 3, a stoveburner 4, and a toaster 1. [SEP] You arrive at drawer 11. The drawer 11 is closed. [SEP] go to drawer 11 [SEP] You open the drawer 11. The drawer 11 is open. In it, you see nothing. [SEP] open drawer 11 [SEP] You close the drawer 11. [SEP] close drawer 11', '-= Welcome to TextWorld, ALFRED! =- You are in the middle of a room. Looking quickly around you, you see a cabinet 1, a cabinet 2, a cabinet 3, a cabinet 4, a cabinet 5, a cabinet 6, a cabinet 7, a cabinet 8, a cabinet 9, a coffeemachine 1, a countertop 1, a countertop 2, a drawer 1, a drawer 10, a drawer 11, a drawer 12, a drawer 13, a drawer 2, a drawer 3, a drawer 4, a drawer 5, a drawer 6, a drawer 7, a drawer 8, a drawer 9, a fridge 1, a garbagecan 1, a microwave 1, a sinkbasin 1, a stoveburner 1, a stoveburner 2, a stoveburner 3, a stoveburner 4, a stoveburner 5, a stoveburner 6, and a toaster 1. [SEP] You close the drawer 12. [SEP] close drawer 12 [SEP] You arrive at drawer 10. On the drawer 10, you see nothing. [SEP] go to drawer 10 [SEP] You arrive at drawer 12. The drawer 12 is closed. [SEP] go to drawer 12']\n",
    "task_desc_strings = ['put a cool plate in cabinet.', 'put two spatula in drawer.', 'put a clean butterknife in drawer.']\n",
    "Actions = ['go to cabinet 12', 'go to countertop 3', 'open drawer 12']\n",
    "\n",
    "commands, _ = generator.command_generation_lama(observation_strings, task_desc_strings)\n",
    "\n",
    "for cmd, baseline in zip(commands, Actions):\n",
    "    print(f\"Generated Command: {cmd} \")\n",
    "    print(f\"Baseline Command: {baseline}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alfworld",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
