{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ffefbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/master/13/danzel/anaconda3/envs/alfworld/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "class LLaMACommandGenerator:\n",
    "    role_text: str = \"\"\n",
    "    action_text: str = \"You can use the following actions:\" \\\n",
    "    \" 1. **go to [object]**: Move to the specified object. \" \\\n",
    "    \" 2. **open [object]**: Open the specified object. \" \\\n",
    "    \" 3. **close [object]**: Close the specified object. \" \\\n",
    "    \" 4. **look**: Look around your current location. \" \\\n",
    "    \" 5. **take [object] from [container]**: Pick up an object from a receptacle. \" \\\n",
    "    \" 6. **move [object] to [location]**: Move an object to a target location. \" \\\n",
    "    \" 7. **put [object] in/on [container]**: Place an object into or onto another object. \" \\\n",
    "    \" 8. **examine [object]**: Examine an object or container to get more information. \" \\\n",
    "    \" 9. **use [object]**: Interact with a toggleable object (e.g., turn on a lamp). \" \\\n",
    "    \"10. **heat [object] with [appliance]**: Heat an object using something like a microwave. \" \\\n",
    "    \"11. **clean [object] with [appliance]**: Clean an object using a sink or basin. \" \\\n",
    "    \"12. **cool [object] with [appliance]**: Cool an object using a fridge. \" \\\n",
    "    \"13. **slice [object] with [tool]**: Slice an object using a knife or similar tool.\"\n",
    "    \n",
    "    def __init__(self, model_name=\"meta-llama/Meta-Llama-3-8B\", device=\"cuda\", save_name=\"lama-8b\"):\n",
    "        self.device = device if torch.cuda.is_available() and device == \"cuda\" else \"cpu\"\n",
    "        # set gpu id\n",
    "        if self.device == \"cuda\":\n",
    "            torch.cuda.set_device(4)\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True)\n",
    "\n",
    "        # Fix missing pad token\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            device_map=None,\n",
    "            torch_dtype=torch.float16 if self.device == \"cuda\" else torch.float32\n",
    "        )\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        self.save_name = save_name\n",
    "    \n",
    "    @classmethod\n",
    "    def read_my_file(cls):\n",
    "        # Read \"role.txt\" from the same folder as this script\n",
    "        try:\n",
    "            folder = Path(__file__).parent  # works only in .py files\n",
    "        except NameError:\n",
    "            folder = Path.cwd()             # fallback for notebooks or interactive mode\n",
    "        file_path = folder / \"role.txt\"\n",
    "        text = file_path.read_text()\n",
    "        # 2. assign to cls.role_prompt\n",
    "        cls.role_text = text\n",
    "    \n",
    "    def generata_prompt(self, obs, task):\n",
    "        \"\"\"\n",
    "        Step 1: Select a role prompt based on task description. -> done\n",
    "        Step 2: [SEP] refers to previous action or observation, group them to previous actions.\n",
    "        Step 3: Regulate user output to only one comaand with templates - alfred.twl2.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Step 1: select role prompt based on task description\n",
    "        if \"put a\" in task or \"put some\" in task:\n",
    "            # Pick & Place\n",
    "            role_prompt = self.__class__.role_text.split(\"**Pick & Place**\")[1].split(\"---\")[0].strip()\n",
    "        elif \"look at\" in task or \"examine\" in task:\n",
    "            # Examine in Light\n",
    "            role_prompt = self.__class__.role_text.split(\"**Examine in Light**\")[1].split(\"---\")[0].strip()\n",
    "        elif \"clean\" in task and \"put\" in task:\n",
    "            # Clean & Place\n",
    "            role_prompt = self.__class__.role_text.split(\"**Clean & Place**\")[1].split(\"---\")[0].strip()\n",
    "        elif \"heat\" in task and \"put\" in task:\n",
    "            # Heat & Place\n",
    "            role_prompt = self.__class__.role_text.split(\"**Heat & Place**\")[1].split(\"---\")[0].strip()\n",
    "        elif \"cool\" in task and \"put\" in task:\n",
    "            # Cool & Place\n",
    "            role_prompt = self.__class__.role_text.split(\"**Cool & Place**\")[1].split(\"---\")[0].strip()\n",
    "        elif \"put two\" in task or \"find two\" in task:\n",
    "            # Pick Two & Place\n",
    "            role_prompt = self.__class__.role_text.split(\"**Pick Two & Place**\")[1].split(\"---\")[0].strip()\n",
    "        else:\n",
    "            role_prompt = \"\"  # fallback or raise an error/log warning\n",
    "\n",
    "        # Step 2: Group previous actions and observations\n",
    "        obs_split = obs.split(\"[SEP]\")\n",
    "        env_prompt = obs_split[0].strip()  # Initial environment description\n",
    "        observations = [s.strip() for s in obs_split[1:] if s.strip()]  # Filter out empty strings\n",
    "        \n",
    "        prompt = f\"{role_prompt}\\n\\n\"\n",
    "        prompt += f\"Environment: {env_prompt}\\n\"\n",
    "        prompt += f\"\\nTask: {task}\\n\"\n",
    "        prompt += \"Previous Actions and Observations:\\n\"\n",
    "        for i, observation in enumerate(observations):\n",
    "            if i % 2 == 0:\n",
    "                prompt += f\"Observation {i//2 + 1}: {observation}\\n\"\n",
    "            else:\n",
    "                prompt += f\"Action {i//2 + 1}: {observation}\\n\"\n",
    "        \n",
    "        prompt += self.__class__.action_text + \"\\n\"\n",
    "        prompt += \"Please follow your role to choose one action.\\n\"\n",
    "        prompt += \"Action: \"\n",
    "        return prompt\n",
    "\n",
    "    def command_generation_lama(self, observation_strings, task_desc_strings):\n",
    "        res = []\n",
    "        read_my_file = self.__class__.read_my_file\n",
    "        if not hasattr(self.__class__, 'role_text') or not self.__class__.role_text:\n",
    "            read_my_file()\n",
    "        if not self.__class__.role_text:\n",
    "            raise ValueError(\"Role text not loaded. Please ensure 'role.txt' is present in the same directory as this script.\")\n",
    "        \n",
    "        for obs, task in zip(observation_strings, task_desc_strings):\n",
    "            # Construct prompt\n",
    "            prompt = self.generata_prompt(obs, task)\n",
    "\n",
    "            # Tokenize prompt (no padding needed for single input)\n",
    "            input_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=1028, return_attention_mask=True).to(self.device)\n",
    "            attention_mask = (input_ids != self.tokenizer.pad_token_id).long()\n",
    "\n",
    "            # Generate response (small token limit for speed)\n",
    "            with torch.no_grad():\n",
    "                output_ids = self.model.generate(\n",
    "                    input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    max_new_tokens=1028,\n",
    "                    temperature=0.7,\n",
    "                    top_p=1.0,\n",
    "                    do_sample=True,\n",
    "                    pad_token_id=self.tokenizer.eos_token_id\n",
    "                )\n",
    "\n",
    "            # Decode and remove the prompt prefix\n",
    "            generated_text = self.tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "            # response_text = generated_text[len(prompt):].strip()\n",
    "            \n",
    "            # response_text = response_text.split(\"\\n\")[0].strip()\n",
    "\n",
    "            res.append(generated_text)\n",
    "            # res.append(response_text)\n",
    "\n",
    "        return res, None  # current_dynamics is unused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "901c2657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/master/13/danzel/anaconda3/envs/alfworld/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py:898: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.29it/s]\n"
     ]
    }
   ],
   "source": [
    "generator = LLaMACommandGenerator(model_name=\"meta-llama/Meta-Llama-3-8B\", device=\"cuda\", save_name=\"lama-8b\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7080f596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Command: You are an embodied agent whose job is to execute “Pick & Place” tasks. Given a natural‐language instruction like “put a plate on the coffee table,” you must:\n",
      "1. Identify an object of the specified type in the scene.\n",
      "2. Issue a command to navigate to that object and pick it up.\n",
      "3. Determine the correct destination (e.g., the coffee table) and navigate there.\n",
      "4. Issue a command to place the object down in the designated location.\n",
      "   Now, given the current textual observation of the environment, produce exactly one next high‐level action (e.g., “go to cabinet 2,” “pick up plate,” “go to coffee table,” or “put down plate”) that advances the “Pick & Place” objective.\n",
      "\n",
      "Environment: -= Welcome to TextWorld, ALFRED! =- You are in the middle of a room. Looking quickly around you, you see a cabinet 1, a cabinet 10, a cabinet 11, a cabinet 12, a cabinet 2, a cabinet 3, a cabinet 4, a cabinet 5, a cabinet 6, a cabinet 7, a cabinet 8, a cabinet 9, a coffeemachine 1, a countertop 1, a countertop 2, a diningtable 1, a drawer 1, a drawer 2, a drawer 3, a fridge 1, a garbagecan 1, a microwave 1, a sinkbasin 1, a stoveburner 1, a stoveburner 2, a stoveburner 3, a stoveburner 4, and a toaster 1.\n",
      "\n",
      "Task: put a cool plate in cabinet.\n",
      "Previous Actions and Observations:\n",
      "Observation 1: You arrive at cabinet 12. The cabinet 12 is closed.\n",
      "Action 1: go to cabinet 12\n",
      "Observation 2: You open the cabinet 12. The cabinet 12 is open. In it, you see a bowl 3.\n",
      "Action 2: open cabinet 12\n",
      "Observation 3: You close the cabinet 12.\n",
      "Action 3: close cabinet 12\n",
      "You can use the following actions: 1. **go to [object]**: Move to the specified object.  2. **open [object]**: Open the specified object.  3. **close [object]**: Close the specified object.  4. **look**: Look around your current location.  5. **take [object] from [container]**: Pick up an object from a receptacle.  6. **move [object] to [location]**: Move an object to a target location.  7. **put [object] in/on [container]**: Place an object into or onto another object.  8. **examine [object]**: Examine an object or container to get more information.  9. **use [object]**: Interact with a toggleable object (e.g., turn on a lamp). 10. **heat [object] with [appliance]**: Heat an object using something like a microwave. 11. **clean [object] with [appliance]**: Clean an object using a sink or basin. 12. **cool [object] with [appliance]**: Cool an object using a fridge. 13. **slice [object] with [tool]**: Slice an object using a knife or similar tool.\n",
      "Please follow your role to choose one action.\n",
      "Action: 1\n",
      "Observation: You arrive at cabinet 10. The cabinet 10 is closed.\n",
      " \n",
      "Baseline Command: go to cabinet 12\n",
      "Generated Command: You are an embodied agent designed for “Pick Two & Place” tasks. When given a task such as “put two pencils in the drawer,” your procedure is:\n",
      "1. Locate an object of the specified type (a pencil) and pick it up.\n",
      "2. Navigate to the target location (a drawer) and put down the first pencil.\n",
      "3. Return to find another object of the same type (the second pencil) elsewhere.\n",
      "4. Pick up the second pencil and return to the original drawer.\n",
      "5. Put down the second pencil alongside the first.\n",
      "   Based on the current observation, generate exactly one next high‐level command (for instance, “go to pencil 1,” “pick up pencil 1,” “go to drawer 2,” “put down pencil 1,” “go to pencil 3,” or “put down pencil 3”) that advances you toward accomplishing the “Pick Two & Place” goal.\n",
      "\n",
      "Environment: -= Welcome to TextWorld, ALFRED! =- You are in the middle of a room. Looking quickly around you, you see a cabinet 1, a cabinet 10, a cabinet 11, a cabinet 12, a cabinet 13, a cabinet 14, a cabinet 15, a cabinet 16, a cabinet 17, a cabinet 18, a cabinet 19, a cabinet 2, a cabinet 20, a cabinet 21, a cabinet 22, a cabinet 23, a cabinet 24, a cabinet 25, a cabinet 26, a cabinet 3, a cabinet 4, a cabinet 5, a cabinet 6, a cabinet 7, a cabinet 8, a cabinet 9, a coffeemachine 1, a countertop 1, a countertop 2, a countertop 3, a drawer 1, a drawer 10, a drawer 11, a drawer 12, a drawer 2, a drawer 3, a drawer 4, a drawer 5, a drawer 6, a drawer 7, a drawer 8, a drawer 9, a fridge 1, a garbagecan 1, a microwave 1, a sinkbasin 1, a stoveburner 1, a stoveburner 2, a stoveburner 3, a stoveburner 4, and a toaster 1.\n",
      "\n",
      "Task: put two spatula in drawer.\n",
      "Previous Actions and Observations:\n",
      "Observation 1: You arrive at drawer 11. The drawer 11 is closed.\n",
      "Action 1: go to drawer 11\n",
      "Observation 2: You open the drawer 11. The drawer 11 is open. In it, you see nothing.\n",
      "Action 2: open drawer 11\n",
      "Observation 3: You close the drawer 11.\n",
      "Action 3: close drawer 11\n",
      "You can use the following actions: 1. **go to [object]**: Move to the specified object.  2. **open [object]**: Open the specified object.  3. **close [object]**: Close the specified object.  4. **look**: Look around your current location.  5. **take [object] from [container]**: Pick up an object from a receptacle.  6. **move [object] to [location]**: Move an object to a target location.  7. **put [object] in/on [container]**: Place an object into or onto another object.  8. **examine [object]**: Examine an object or container to get more information.  9. **use [object]**: Interact with a toggleable object (e.g., turn on a lamp). 10. **heat [object] with [appliance]**: Heat an object using something like a microwave. 11. **clean [object] with [appliance]**: Clean an object using a sink or basin. 12. **cool [object] with [appliance]**: Cool an object using a fridge. 13. **slice [object] with [tool]**: Slice an object using a knife or similar tool.\n",
      "Please follow your role to choose one action.\n",
      "Action: 4\n",
      "Observation 4: You're standing in the middle of a room. Looking quickly around you, you see a cabinet 1, a cabinet 10, a cabinet 11, a cabinet 12, a cabinet 13, a cabinet 14, a cabinet 15, a cabinet 16, a cabinet 17, a cabinet 18, a cabinet 19, a cabinet 2, a cabinet 20, a cabinet 21, a cabinet 22, a cabinet 23, a cabinet 24, a cabinet 25, a cabinet 26, a cabinet 3, a cabinet 4, a cabinet 5, a cabinet 6, a cabinet 7, a cabinet 8, a cabinet 9, a coffeemachine 1, a countertop 1, a countertop 2, a countertop 3, a drawer 1, a drawer 10, a drawer 11, a drawer 12, a drawer 2, a drawer 3, a drawer 4, a drawer 5, a drawer 6, a drawer 7, a drawer 8, a drawer 9, a fridge 1, a garbagecan 1, a microwave 1, a sinkbasin 1, a stoveburner 1, a stoveburner 2, a stoveburner 3, a stoveburner 4, and a toaster 1.\n",
      "Previous Actions and Observations:\n",
      "Observation 1: You arrive at drawer 11. The drawer 11 is closed.\n",
      "Action 1: go to drawer 11\n",
      "Observation 2: You open the drawer 11. The drawer 11 is open. In it, you see nothing.\n",
      "Action 2: open drawer 11\n",
      "Observation 3: You close the drawer 11.\n",
      "Action 3: close drawer 11\n",
      "Observation 4: You're standing in the middle of a room. Looking quickly around you, you see a cabinet 1, a cabinet 10, a cabinet 11, a cabinet 12, a cabinet 13, a cabinet 14, a cabinet 15, a cabinet 16, a cabinet 17, a cabinet 18, a cabinet 19, a cabinet 2, a cabinet 20, a cabinet 21, a cabinet 22, a cabinet 23, a cabinet 24, a cabinet 25, a cabinet 26, a cabinet 3, a cabinet 4, a cabinet 5, a cabinet 6, a cabinet 7, a cabinet 8, a cabinet 9, a coffeemachine 1, a countertop 1, a countertop 2, a countertop 3, a drawer 1, a drawer 10, a drawer 11, a drawer 12, a drawer 2, a drawer 3, a drawer 4, a drawer 5, a drawer 6, a drawer 7, a drawer 8, a drawer 9, a fridge 1, a garbagecan 1, a microwave 1, a sinkbasin 1, a stoveburner 1, a stoveburner 2, a stoveburner 3, a stoveburner 4, and a toaster 1.\n",
      "\n",
      "Action: 11\n",
      "Observation 5: You arrive at fridge 1. The fridge 1 is closed.\n",
      "Action 5: go to fridge 1\n",
      "Observation 6: You open the fridge 1. The fridge 1 is open. In it, you see a cheese, a cucumber, a mushroom, and a salad.\n",
      "Action 6: open fridge 1\n",
      "Observation 7: You close the fridge 1.\n",
      "Action 7: close fridge 1\n",
      "Observation 8: You're standing in the middle of a room. Looking quickly around you, you see a cabinet 1, a cabinet 10, a cabinet 11, a cabinet 12, a cabinet 13, a cabinet 14, a cabinet 15, a cabinet 16, a cabinet 17, a cabinet 18, a cabinet 19, a cabinet 2, a cabinet 20, a cabinet 21, a cabinet 22, a cabinet 23, a cabinet 24, a cabinet 25, a cabinet 26, a cabinet 3, a cabinet 4, a cabinet 5, a cabinet 6, a cabinet 7, a cabinet 8, a cabinet 9, a coffeemachine 1, a countertop 1, a countertop 2, a countertop 3, a drawer 1, a drawer 10, a drawer 11, a drawer 12, a drawer 2, a drawer 3, a drawer 4, a drawer 5, a drawer 6, a drawer 7, a drawer 8, a drawer 9, a fridge 1, a garbagecan  \n",
      "Baseline Command: go to countertop 3\n",
      "Generated Command: You are an embodied agent whose job is to execute “Pick & Place” tasks. Given a natural‐language instruction like “put a plate on the coffee table,” you must:\n",
      "1. Identify an object of the specified type in the scene.\n",
      "2. Issue a command to navigate to that object and pick it up.\n",
      "3. Determine the correct destination (e.g., the coffee table) and navigate there.\n",
      "4. Issue a command to place the object down in the designated location.\n",
      "   Now, given the current textual observation of the environment, produce exactly one next high‐level action (e.g., “go to cabinet 2,” “pick up plate,” “go to coffee table,” or “put down plate”) that advances the “Pick & Place” objective.\n",
      "\n",
      "Environment: -= Welcome to TextWorld, ALFRED! =- You are in the middle of a room. Looking quickly around you, you see a cabinet 1, a cabinet 2, a cabinet 3, a cabinet 4, a cabinet 5, a cabinet 6, a cabinet 7, a cabinet 8, a cabinet 9, a coffeemachine 1, a countertop 1, a countertop 2, a drawer 1, a drawer 10, a drawer 11, a drawer 12, a drawer 13, a drawer 2, a drawer 3, a drawer 4, a drawer 5, a drawer 6, a drawer 7, a drawer 8, a drawer 9, a fridge 1, a garbagecan 1, a microwave 1, a sinkbasin 1, a stoveburner 1, a stoveburner 2, a stoveburner 3, a stoveburner 4, a stoveburner 5, a stoveburner 6, and a toaster 1.\n",
      "\n",
      "Task: put a clean butterknife in drawer.\n",
      "Previous Actions and Observations:\n",
      "Observation 1: You close the drawer 12.\n",
      "Action 1: close drawer 12\n",
      "Observation 2: You arrive at drawer 10. On the drawer 10, you see nothing.\n",
      "Action 2: go to drawer 10\n",
      "Observation 3: You arrive at drawer 12. The drawer 12 is closed.\n",
      "Action 3: go to drawer 12\n",
      "You can use the following actions: 1. **go to [object]**: Move to the specified object.  2. **open [object]**: Open the specified object.  3. **close [object]**: Close the specified object.  4. **look**: Look around your current location.  5. **take [object] from [container]**: Pick up an object from a receptacle.  6. **move [object] to [location]**: Move an object to a target location.  7. **put [object] in/on [container]**: Place an object into or onto another object.  8. **examine [object]**: Examine an object or container to get more information.  9. **use [object]**: Interact with a toggleable object (e.g., turn on a lamp). 10. **heat [object] with [appliance]**: Heat an object using something like a microwave. 11. **clean [object] with [appliance]**: Clean an object using a sink or basin. 12. **cool [object] with [appliance]**: Cool an object using a fridge. 13. **slice [object] with [tool]**: Slice an object using a knife or similar tool.\n",
      "Please follow your role to choose one action.\n",
      "Action: 5\n",
      "Observation 4: You take the clean butterknife from the drawer 12.\n",
      "Action 5: take clean butterknife from drawer 12\n",
      "You can use the following actions: 1. **go to [object]**: Move to the specified object.  2. **open [object]**: Open the specified object.  3. **close [object]**: Close the specified object.  4. **look**: Look around your current location.  5. **take [object] from [container]**: Pick up an object from a receptacle.  6. **move [object] to [location]**: Move an object to a target location.  7. **put [object] in/on [container]**: Place an object into or onto another object.  8. **examine [object]**: Examine an object or container to get more information.  9. **use [object]**: Interact with a toggleable object (e.g., turn on a lamp). 10. **heat [object] with [appliance]**: Heat an object using something like a microwave. 11. **clean [object] with [appliance]**: Clean an object using a sink or basin. 12. **cool [object] with [appliance]**: Cool an object using a fridge. 13. **slice [object] with [tool]**: Slice an object using a knife or similar tool.\n",
      "Please follow your role to choose one action.\n",
      "Action: 6\n",
      "Observation 5: You arrive at the countertop 1. On the countertop 1, you see nothing.\n",
      "Action 6: go to countertop 1\n",
      "You can use the following actions: 1. **go to [object]**: Move to the specified object.  2. **open [object]**: Open the specified object.  3. **close [object]**: Close the specified object.  4. **look**: Look around your current location.  5. **take [object] from [container]**: Pick up an object from a receptacle.  6. **move [object] to [location]**: Move an object to a target location.  7. **put [object] in/on [container]**: Place an object into or onto another object.  8. **examine [object]**: Examine an object or container to get more information.  9. **use [object]**: Interact with a toggleable object (e.g., turn on a lamp). 10. **heat [object] with [appliance]**: Heat an object using something like a microwave. 11. **clean [object] with [appliance]**: Clean an object using a sink or basin. 12. **cool [object] with [appliance]**: Cool an object using a fridge. 13. **slice [object] with [tool]**: Slice an object using a knife or similar tool.\n",
      "Please follow your role to choose one action.\n",
      "Action: 7\n",
      "Observation 6: You put the clean butterknife in the countertop 1.\n",
      "Action 7: put clean butterknife in countertop 1\n",
      "You can use the following actions: 1. **go to [object]**: Move to the specified object.  2. **open [object]**: Open the specified object.  3. **close [object]**: Close the specified object.  4. **look**: Look around your current location.  5. **take [object] from [container]**: Pick up an object from a receptacle.  6. **move [object] to [location]**: Move an object to a target location.  7. **put [object] in/on [container]**: Place an object into or onto another object.  8. **examine [object]**: Examine an object or container to get more information.  9. **use [object]**: Interact with a toggleable object (e.g., turn on a lamp). 10. **heat [object] with [appliance]**: Heat an object using something like a microwave. 11. **clean [object] with [appliance]**: Clean an object using a sink or basin. 12. **cool [object] with [appliance]**: Cool an object using a fridge. 13. **slice [object] with [tool]**: Slice an object using a knife or similar tool.\n",
      "Please follow your role to choose one action.\n",
      "Action: 8\n",
      "Observation 7: You examine the countertop 1. On the countertop 1, you see a clean butterknife, a dirty fork, a dirty knife, and a dirty plate.\n",
      "Action 8: examine countertop 1\n",
      "You can use the following actions: 1. **go to [object]**: Move to the specified object \n",
      "Baseline Command: open drawer 12\n"
     ]
    }
   ],
   "source": [
    "observation_strings = ['-= Welcome to TextWorld, ALFRED! =- You are in the middle of a room. Looking quickly around you, you see a cabinet 1, a cabinet 10, a cabinet 11, a cabinet 12, a cabinet 2, a cabinet 3, a cabinet 4, a cabinet 5, a cabinet 6, a cabinet 7, a cabinet 8, a cabinet 9, a coffeemachine 1, a countertop 1, a countertop 2, a diningtable 1, a drawer 1, a drawer 2, a drawer 3, a fridge 1, a garbagecan 1, a microwave 1, a sinkbasin 1, a stoveburner 1, a stoveburner 2, a stoveburner 3, a stoveburner 4, and a toaster 1. [SEP] You arrive at cabinet 12. The cabinet 12 is closed. [SEP] go to cabinet 12 [SEP] You open the cabinet 12. The cabinet 12 is open. In it, you see a bowl 3. [SEP] open cabinet 12 [SEP] You close the cabinet 12. [SEP] close cabinet 12', '-= Welcome to TextWorld, ALFRED! =- You are in the middle of a room. Looking quickly around you, you see a cabinet 1, a cabinet 10, a cabinet 11, a cabinet 12, a cabinet 13, a cabinet 14, a cabinet 15, a cabinet 16, a cabinet 17, a cabinet 18, a cabinet 19, a cabinet 2, a cabinet 20, a cabinet 21, a cabinet 22, a cabinet 23, a cabinet 24, a cabinet 25, a cabinet 26, a cabinet 3, a cabinet 4, a cabinet 5, a cabinet 6, a cabinet 7, a cabinet 8, a cabinet 9, a coffeemachine 1, a countertop 1, a countertop 2, a countertop 3, a drawer 1, a drawer 10, a drawer 11, a drawer 12, a drawer 2, a drawer 3, a drawer 4, a drawer 5, a drawer 6, a drawer 7, a drawer 8, a drawer 9, a fridge 1, a garbagecan 1, a microwave 1, a sinkbasin 1, a stoveburner 1, a stoveburner 2, a stoveburner 3, a stoveburner 4, and a toaster 1. [SEP] You arrive at drawer 11. The drawer 11 is closed. [SEP] go to drawer 11 [SEP] You open the drawer 11. The drawer 11 is open. In it, you see nothing. [SEP] open drawer 11 [SEP] You close the drawer 11. [SEP] close drawer 11', '-= Welcome to TextWorld, ALFRED! =- You are in the middle of a room. Looking quickly around you, you see a cabinet 1, a cabinet 2, a cabinet 3, a cabinet 4, a cabinet 5, a cabinet 6, a cabinet 7, a cabinet 8, a cabinet 9, a coffeemachine 1, a countertop 1, a countertop 2, a drawer 1, a drawer 10, a drawer 11, a drawer 12, a drawer 13, a drawer 2, a drawer 3, a drawer 4, a drawer 5, a drawer 6, a drawer 7, a drawer 8, a drawer 9, a fridge 1, a garbagecan 1, a microwave 1, a sinkbasin 1, a stoveburner 1, a stoveburner 2, a stoveburner 3, a stoveburner 4, a stoveburner 5, a stoveburner 6, and a toaster 1. [SEP] You close the drawer 12. [SEP] close drawer 12 [SEP] You arrive at drawer 10. On the drawer 10, you see nothing. [SEP] go to drawer 10 [SEP] You arrive at drawer 12. The drawer 12 is closed. [SEP] go to drawer 12']\n",
    "task_desc_strings = ['put a cool plate in cabinet.', 'put two spatula in drawer.', 'put a clean butterknife in drawer.']\n",
    "Actions = ['go to cabinet 12', 'go to countertop 3', 'open drawer 12']\n",
    "\n",
    "\n",
    "commands, _ = generator.command_generation_lama(observation_strings, task_desc_strings)\n",
    "\n",
    "for cmd, baseline in zip(commands, Actions):\n",
    "    print(f\"Generated Command: {cmd} \")\n",
    "    print(f\"Baseline Command: {baseline}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alfworld",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
